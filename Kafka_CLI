important for kafka running in docker

>docker exec -it kafka bash

find the ip of both container i.e docker and zookeeper

with >docker ps  we can find image number

>docker inspect 8dcc00fcad65 | grep "IPAddress"

            "SecondaryIPAddresses": null,
            "IPAddress": "",
                    "IPAddress": "172.19.0.2",

create topic
>kafka-topics --zookeeper 172.19.0.2:2181 --topic first_topic --create --partitions 3 --replication-factor 2

list topic

> kafka-topics --zookeeper 172.19.0.2:2181



kafka-topics  --create  --bootstrap-server localhost:9092  --replication-factor 1 --partitions 3 --topic users



KAFKA_HOME/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 --version
üê≥ Example to execute in Docker:
./usr/bin/kafka-broker-api-versions --bootstrap-server localhost:9092 --version
Connect to Zookeeper
Apache Kafka is depending* on Apache Zookeeper for:
cluster membership
controller election
topic configuration
access control lists
quotas.
The meta-data for those operations are stored outside of Kafka in a separate Zookeeper cluster.
* from version 2.8 onwards Apache Kafka is not depending on Zookeeper anymore. For more details see: Apache Kafka Needs No Keeper: Removing the Apache ZooKeeper Dependency on the Confluent blog.
To be able to see metadata of the Kafka cluster from Zookeeper first connect to Zookeeper using the zookeeper-shell command that ships with the Kafka distribution.
$KAFKA_HOME/bin/zookeeper-shell.sh $ZK_HOSTS:2181
üê≥ Example to execute in Docker:
./usr/bin/zookeeper-shell zookeeper:2181
Output:
Connecting to zookeeper:2181
Welcome to ZooKeeper!
JLine support is disabled
WATCHER::
WatchedEvent state:SyncConnected type:None path:null
You are now connected to the ZooKeeper cluster.
Show the Kafka cluster id
$KAFKA_HOME/bin/zookeeper-shell $ZK_HOSTS:2181 get /cluster/id
üê≥ Example to execute in Docker:
./usr/bin/zookeeper-shell zookeeper:2181 get /cluster/id
Output:
Connecting to zookeeper:2181
WATCHER::
WatchedEvent state:SyncConnected type:None path:null
{"version":"1","id":"cDpWBoJpQraTnNqSwB_4Tg"}
In this example, the id of the Kafka cluster is: cpWBoJpQraTnNqSwB_4Tg
List brokers in the Kafka cluster cluster
Let‚Äôs list the broker in the Kafka cluster
ls /brokers/ids
Output:
[1]
In my docker setup, there is only one Kafka broker in the cluster.
The id of the Kafka broker is: 1
Show details of a Kafka broker
get /brokers/ids/1
Show all the topics that exist in the cluster
ls /brokers/topics
Output:
[my-first-topic]
Show details of a specific topic
get /brokers/topics/my-first-topic
Exit the zookeeper shell
exit
Topics
In this chapter, you find the CLI command and options that are related to Kafka topics.
Create a Kafka topic
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper $ZK_HOSTS --create --topic $TOPIC_NAME --partitions 3 --replication-factor 3
üê≥ Example to execute in Docker:
./usr/bin/kafka-topics --zookeeper zookeeper:2181 --create --topic my-first-topic --partitions 3 --replication-factor 1
Create a Kafka topic in case the topic doesn‚Äôt exist
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper $ZK_HOSTS --create --topic $TOPIC_NAME --partitions 3 --replication-factor 3 --if-not-exists
üê≥ Example to execute in Docker:
./usr/bin/kafka-topics --zookeeper zookeeper:2181 --create --topic my-first-topic --partitions 3 --replication-factor 1 --if-not-exists
Note the CLI will not give an error in case the topic already exists.
List Kafka topics
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper $ZK_HOSTS --list
üê≥ Example to execute in Docker:
./usr/bin/kafka-topics --zookeeper zookeeper:2181 --list
List Kafka topics and exclude internal topics
Exclude listing of external topics like ‚Äú__consumer_offsets‚Äù
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper $ZK_HOSTS --list --exclude-internal
üê≥ Example to execute in Docker:
./usr/bin/kafka-topics --zookeeper zookeeper:2181 --list --exclude-internal
Show the Kafka topic details
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper $ZK_HOSTS
--topic $TOPIC_NAME --describe
üê≥ Example to execute in Docker:
./usr/bin/kafka-topics --zookeeper zookeeper:2181 --topic my-first-topic --describe
Increase the number of partitions of a Kafka topic
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper $ZK_HOSTS
--alter --topic my-first-topic --partitions 5
üê≥ Example to execute in Docker:
./usr/bin/kafka-topics --zookeeper zookeeper:2181 --alter --topic my-first-topic --partitions 5
Note:
The number of partitions for a topic can only be increased.
If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected.
Change the retention time of a Kafka topic
259200000 ms = 3 days
$KAFKA_HOME/bin/kafka-configs.sh --zookeeper $ZK_HOSTS --alter --entity-type topics --entity-name my-first-topic --add-config retention.ms=259200000
üê≥ Example to execute in Docker:
./usr/bin/kafka-configs --zookeeper zookeeper:2181 --alter --entity-type topics --entity-name my-first-topic --add-config retention.ms=259200000
Purge a Kafka topic
At the time of writing, there is no single command to purge a topic.
As a workaround, you can purge a topic by changing the retention time of a topic to one minute.
$KAFKA_HOME/bin/kafka-configs.sh --zookeeper $ZK_HOSTS --alter --entity-type topics --entity-name my-first-topic --add-config retention.ms=1000
Wait one minute. Kafka will now remove records older than one minute from the topic. Now delete the retention.ms configuration from the topic so it will default back to the retention configuration of the Kafka cluster. The default retention period of a Kafka topic is seven days (unless you configured it differently).
$KAFKA_HOME/bin/kafka-configs.sh --zookeeper $ZK_HOSTS --alter --entity-type topics --entity-name my-first-topic --delete-config retention.ms
In case you had a specific retention period specified on the topic. You need to apply that retention period again (in this example 3 days retention period)
$KAFKA_HOME/bin/kafka-configs.sh --zookeeper $ZK_HOSTS --alter --entity-type topics --entity-name my-first-topic --add-config retention.ms=259200000
üê≥ Example to execute in Docker:
./usr/bin/kafka-configs --zookeeper zookeeper:2181 --alter --entity-type topics --entity-name my-first-topic --add-config retention.ms=1000
Wait one minute:
./usr/bin/kafka-configs --zookeeper zookeeper:2181 --alter --entity-type topics --entity-name my-first-topic --delete-config retention.ms
List Kafka topics (with configuration values) that have specific configuration overrides
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper $ZK_HOSTS --describe --topics-with-overrides
üê≥ Example to execute in Docker:
./usr/bin/kafka-topics --zookeeper zookeeper:2181 --describe --topics-with-overrides
Show specific Kafka topic configuration overrides
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper $ZK_HOSTS --describe --entity-type topics --entity-name my-first-topic
üê≥ Example to execute in Docker:
./usr/bin/kafka-configs --zookeeper zookeeper:2181 --describe --entity-type topics --entity-name my-first-topic
Note in case there a no particular property overrides for the topic this command will not show default cluster properties applied to the topic.
Delete a Kafka topic
$KAFKA_HOME/bin/kafka-topics.sh ‚Äî zookeeper $ZK_HOSTS --delete
--topic $TOPIC_NAME
üê≥ Example to execute in Docker:
./usr/bin/kafka-topics --zookeeper zookeeper:2181 --delete --topic my-first-topic
Producers
Produce a message to a Kafka topic
$KAFKA_HOME/usr/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic $TOPIC_NAME
A prompt will open:
>
Type in a message and press enter to publish it to the topic:
>Hello World
Note:
Repeat the same step to publish more messages
The message published to Kafka has a null key
Press Ctrl+C to exit
üê≥ Example to execute in Docker:
./usr/bin/kafka-console-producer --broker-list localhost:9092 --topic my-first-topic
Produce messages to a Kafka topic from a file
Example file topic-input.txt (make sure each message is on a new line):
Hello World
Kafka Rocks!
Happy Streaming
Produce messages to the topic from the file:
$KAFKA_HOME/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-first-topic < topic-input.txt
üê≥ Example to execute in Docker:
./usr/bin/kafka-console-producer --broker-list localhost:9092 --topic my-first-topic < topic-input.txt
Produce messages to Kafka with both key and value
By default messages sent to a Kafka topic will result in messages with nullkeys. In this example, the separator between the key and the value is: :
$KAFKA_HOME/usr/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic $TOPIC_NAME --property parse.key=true
--property key.separator=:
üê≥ Example to execute in Docker:
./usr/bin/kafka-console-producer --broker-list localhost:9092 --topic some-topic --property parse.key=true --property key.separator=*
Example input:
>key:value
>foo:bar
>anotherKey:another value
Consumers
Consume a Kafka topic
$KAFKA_HOME/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic $TOPIC_NAME
üê≥ Example to execute in Docker:
./usr/bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic my-first-topic
If a consumer group id is not specified, the kafka-console-consumer generates a random consumer group.
Consume a Kafka topic and show both key and value
By default, the console consumer will only the value of the Kafka record.
Using this command you can show both the key and value.
$KAFKA_HOME/bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic some-topic --formatter kafka.tools.DefaultMessageFormatter --property print.key=true --property print.value=true
üê≥ Example to execute in Docker:
./usr/bin/kafka-console-consumer --bootstrap-server localhost:9092 \    --topic some-topic \
--formatter kafka.tools.DefaultMessageFormatter \
--property print.key=true \
--property print.value=true
Consume a Kafka topic from the beginning
$KAFKA_HOME/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-first-topic --from-beginning
üê≥ Example to execute in Docker:
./usr/bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic my-first-topic --from-beginning
Miscellaneous
Find all the partitions where one or more of the replicas for the partition are not in-sync with the leader.
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --under-replicated-partitions
üê≥ Example to execute in Docker:
./usr/bin/kafka-topics --zookeeper zookeeper:2181 --describe --under-replicated-partitions




